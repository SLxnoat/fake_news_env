{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679e8936-0d80-4734-a224-1b13fb51a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Starting TF-IDF Model Development...\n"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "import os\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "print(\"ü§ñ Starting TF-IDF Model Development...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3e3684-e44e-4d9c-b631-541db2c87506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading cleaned data from Member 1...\n",
      "‚ùå Cleaned data not found!\n",
      "Please run Member 1's notebook first (01_data_cleaning.ipynb)\n",
      "\n",
      "üîç Data Quality Check:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Check data quality\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîç Data Quality Check:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain - Real: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_binary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fake: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_binary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest - Real: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_binary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Fake: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_binary\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Load Cleaned Data\n",
    "\n",
    "print(\"üìä Loading cleaned data from Member 1...\")\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv('../data/train_clean.csv')\n",
    "    test_df = pd.read_csv('../data/test_clean.csv')\n",
    "    valid_df = pd.read_csv('../data/valid_clean.csv')\n",
    "    \n",
    "    print(\"‚úÖ Data loaded successfully!\")\n",
    "    print(f\"Training: {len(train_df)} samples\")\n",
    "    print(f\"Test: {len(test_df)} samples\")\n",
    "    print(f\"Validation: {len(valid_df)} samples\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Cleaned data not found!\")\n",
    "    print(\"Please run Member 1's notebook first (01_data_cleaning.ipynb)\")\n",
    "    exit()\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\nüîç Data Quality Check:\")\n",
    "print(f\"Train - Real: {sum(train_df['label_binary'] == 1)}, Fake: {sum(train_df['label_binary'] == 0)}\")\n",
    "print(f\"Test - Real: {sum(test_df['label_binary'] == 1)}, Fake: {sum(test_df['label_binary'] == 0)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d693fd-3d8d-4865-9cf2-ab82c2bb3433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù TEXT ANALYSIS...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìù TEXT ANALYSIS...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Separate real vs fake news text\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m real_news \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_binary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_statement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m fake_news \u001b[38;5;241m=\u001b[39m train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_binary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_statement\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create word clouds\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Text Analysis and Visualization\n",
    "print(\"\\nüìù TEXT ANALYSIS...\")\n",
    "\n",
    "# Separate real vs fake news text\n",
    "real_news = train_df[train_df['label_binary'] == 1]['clean_statement']\n",
    "fake_news = train_df[train_df['label_binary'] == 0]['clean_statement']\n",
    "\n",
    "# Create word clouds\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "real_text = ' '.join(real_news.astype(str))\n",
    "wordcloud_real = WordCloud(width=400, height=300, background_color='white').generate(real_text)\n",
    "plt.imshow(wordcloud_real, interpolation='bilinear')\n",
    "plt.title('Real News - Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "fake_text = ' '.join(fake_news.astype(str))\n",
    "wordcloud_fake = WordCloud(width=400, height=300, background_color='white').generate(fake_text)\n",
    "plt.imshow(wordcloud_fake, interpolation='bilinear')\n",
    "plt.title('Fake News - Word Cloud')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Text length analysis\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(real_news.str.len(), bins=50, alpha=0.7, label='Real', color='green')\n",
    "plt.hist(fake_news.str.len(), bins=50, alpha=0.7, label='Fake', color='red')\n",
    "plt.title('Statement Length Distribution')\n",
    "plt.xlabel('Characters')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(real_news.str.split().str.len(), bins=50, alpha=0.7, label='Real', color='green')\n",
    "plt.hist(fake_news.str.split().str.len(), bins=50, alpha=0.7, label='Fake', color='red')\n",
    "plt.title('Word Count Distribution')\n",
    "plt.xlabel('Words')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60582e4-373e-43ac-99a3-87d1dfdbab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî§ CREATING TF-IDF FEATURES...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TfidfVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müî§ CREATING TF-IDF FEATURES...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize TF-IDF vectorizer with optimized parameters\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m \u001b[43mTfidfVectorizer\u001b[49m(\n\u001b[0;32m      6\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m,          \u001b[38;5;66;03m# Top 5000 most important words\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m,       \u001b[38;5;66;03m# Remove common English words\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m),         \u001b[38;5;66;03m# Use single words and bigrams\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,                   \u001b[38;5;66;03m# Word must appear at least 2 times\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m,                \u001b[38;5;66;03m# Ignore words that appear in >95% of documents\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,             \u001b[38;5;66;03m# Convert to lowercase\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     strip_accents\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m'\u001b[39m       \u001b[38;5;66;03m# Remove accents\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on training data and transform all datasets\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  üîÑ Fitting TF-IDF on training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#TF-IDF Feature Extraction\n",
    "print(\"\\nüî§ CREATING TF-IDF FEATURES...\")\n",
    "\n",
    "# Initialize TF-IDF vectorizer with optimized parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,          # Top 5000 most important words\n",
    "    stop_words='english',       # Remove common English words\n",
    "    ngram_range=(1, 2),         # Use single words and bigrams\n",
    "    min_df=2,                   # Word must appear at least 2 times\n",
    "    max_df=0.95,                # Ignore words that appear in >95% of documents\n",
    "    lowercase=True,             # Convert to lowercase\n",
    "    strip_accents='ascii'       # Remove accents\n",
    ")\n",
    "\n",
    "# Fit on training data and transform all datasets\n",
    "print(\"  üîÑ Fitting TF-IDF on training data...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['clean_statement'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['clean_statement'])\n",
    "X_valid_tfidf = tfidf_vectorizer.transform(valid_df['clean_statement'])\n",
    "\n",
    "# Get target variables\n",
    "y_train = train_df['label_binary']\n",
    "y_test = test_df['label_binary']\n",
    "y_valid = valid_df['label_binary']\n",
    "\n",
    "print(f\"‚úÖ TF-IDF Features Created:\")\n",
    "print(f\"   Feature dimensions: {X_train_tfidf.shape[1]}\")\n",
    "print(f\"   Training samples: {X_train_tfidf.shape[0]}\")\n",
    "print(f\"   Test samples: {X_test_tfidf.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2191e72-8640-43cb-a427-8697df36ebf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ TRAINING TF-IDF MODELS...\n",
      "\n",
      "üîπ Training Logistic Regression...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Model 1: Logistic Regression\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîπ Training Logistic Regression...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m lr_model \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m     10\u001b[0m lr_model\u001b[38;5;241m.\u001b[39mfit(X_train_tfidf, y_train)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Predictions\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "#Train Multiple Models\n",
    "print(\"\\nüéØ TRAINING TF-IDF MODELS...\")\n",
    "\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Model 1: Logistic Regression\n",
    "print(\"\\nüîπ Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "lr_train_pred = lr_model.predict(X_train_tfidf)\n",
    "lr_test_pred = lr_model.predict(X_test_tfidf)\n",
    "\n",
    "# Store results\n",
    "models['logistic_regression'] = lr_model\n",
    "results['logistic_regression'] = {\n",
    "    'train_accuracy': accuracy_score(y_train, lr_train_pred),\n",
    "    'test_accuracy': accuracy_score(y_test, lr_test_pred),\n",
    "    'predictions': lr_test_pred\n",
    "}\n",
    "\n",
    "print(f\"  ‚úÖ Logistic Regression - Test Accuracy: {results['logistic_regression']['test_accuracy']:.3f}\")\n",
    "\n",
    "# Model 2: Random Forest\n",
    "print(\"\\nüå≤ Training Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "# Predictions\n",
    "rf_train_pred = rf_model.predict(X_train_tfidf)\n",
    "rf_test_pred = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Store results\n",
    "models['random_forest'] = rf_model\n",
    "results['random_forest'] = {\n",
    "    'train_accuracy': accuracy_score(y_train, rf_train_pred),\n",
    "    'test_accuracy': accuracy_score(y_test, rf_test_pred),\n",
    "    'predictions': rf_test_pred\n",
    "}\n",
    "\n",
    "print(f\"  ‚úÖ Random Forest - Test Accuracy: {results['random_forest']['test_accuracy']:.3f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f17fd24-6117-463f-a292-618d1b6f5e75",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:58\u001b[1;36m\u001b[0m\n\u001b[1;33m    plt.barh(range(len(top_features)), top_importances)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation and Comparison\n",
    "print(\"\\nüìä MODEL EVALUATION...\")\n",
    "\n",
    "# Create results comparison\n",
    "comparison_data = []\n",
    "for model_name, model_results in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': model_name.replace('_', ' ').title(),\n",
    "        'Train Accuracy': f\"{model_results['train_accuracy']:.3f}\",\n",
    "        'Test Accuracy': f\"{model_results['test_accuracy']:.3f}\",\n",
    "        'Overfitting': f\"{model_results['train_accuracy'] - model_results['test_accuracy']:.3f}\"\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nüèÜ Model Performance Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Accuracy comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "model_names = [name.replace('_', ' ').title() for name in results.keys()]\n",
    "train_accs = [results[name]['train_accuracy'] for name in results.keys()]\n",
    "test_accs = [results[name]['test_accuracy'] for name in results.keys()]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "plt.bar(x - width/2, train_accs, width, label='Train', color='lightblue')\n",
    "plt.bar(x + width/2, test_accs, width, label='Test', color='darkblue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xticks(x, model_names)\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Best model confusion matrix\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "cm = confusion_matrix(y_test, best_predictions)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.title(f'Confusion Matrix - {best_model_name.replace(\"_\", \" \").title()}')\n",
    "\n",
    "# Feature importance (for Random Forest)\n",
    "if 'random_forest' in models:\n",
    "    plt.subplot(2, 2, 3)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    importances = models['random_forest'].feature_importances_\n",
    "    \n",
    "    # Get top 20 features\n",
    "    top_indices = importances.argsort()[-20:]\n",
    "    top_features = [feature_names[i] for i in top_indices]\n",
    "    top_importances = importances[top_indices]\n",
    " plt.barh(range(len(top_features)), top_importances)\n",
    "    plt.yticks(range(len(top_features)), top_features)\n",
    "    plt.title('Top 20 Important Features')\n",
    "    plt.xlabel('Importance')\n",
    "\n",
    "# Cross-validation scores\n",
    "plt.subplot(2, 2, 4)\n",
    "cv_scores = {}\n",
    "for model_name, model in models.items():\n",
    "    cv_scores[model_name] = cross_val_score(model, X_train_tfidf, y_train, cv=5)\n",
    "\n",
    "cv_means = [np.mean(cv_scores[name]) for name in cv_scores.keys()]\n",
    "cv_stds = [np.std(cv_scores[name]) for name in cv_scores.keys()]\n",
    "\n",
    "plt.bar(range(len(cv_means)), cv_means, yerr=cv_stds, capsize=5)\n",
    "plt.xticks(range(len(cv_means)), [name.replace('_', ' ').title() for name in cv_scores.keys()])\n",
    "plt.title('5-Fold Cross-Validation Scores')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfe6b4d-7d77-46d4-a6aa-770d86a3438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà DETAILED CLASSIFICATION REPORTS...\n"
     ]
    }
   ],
   "source": [
    "#Detailed Classification Report\n",
    "print(\"\\nüìà DETAILED CLASSIFICATION REPORTS...\")\n",
    "\n",
    "for model_name, model_results in results.items():\n",
    "    print(f\"\\nüìä {model_name.replace('_', ' ').title()} Classification Report:\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_test, model_results['predictions'], \n",
    "                              target_names=['Fake', 'Real']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6691f3af-0dbc-4936-b90b-31f37c6b051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ SAVING MODELS...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müíæ SAVING MODELS...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Determine best model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m best_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m best_model \u001b[38;5;241m=\u001b[39m models[best_model_name]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müèÜ Best model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtitle()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "#Save Best Model\n",
    "print(\"\\nüíæ SAVING MODELS...\")\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['test_accuracy'])\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"üèÜ Best model: {best_model_name.replace('_', ' ').title()}\")\n",
    "print(f\"   Test Accuracy: {results[best_model_name]['test_accuracy']:.3f}\")\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the best TF-IDF model and vectorizer\n",
    "joblib.dump(best_model, '../models/tfidf_model.pkl')\n",
    "joblib.dump(tfidf_vectorizer, '../models/tfidf_vectorizer.pkl')\n",
    "\n",
    "# Save all models for comparison\n",
    "for model_name, model in models.items():\n",
    "    joblib.dump(model, f'../models/tfidf_{model_name}.pkl')\n",
    "\n",
    "print(\"‚úÖ Models saved successfully!\")\n",
    "print(\"üìÅ Files created:\")\n",
    "print(\"   - ../models/tfidf_model.pkl (best model)\")\n",
    "print(\"   - ../models/tfidf_vectorizer.pkl\")\n",
    "print(f\"   - ../models/tfidf_logistic_regression.pkl\")\n",
    "print(f\"   - ../models/tfidf_random_forest.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3745ba-185b-4499-ba04-3a02b2b37390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ CREATING MODEL TESTING FUNCTION...\n",
      "\n",
      "üß™ TESTING MODEL WITH SAMPLE STATEMENTS:\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, statement \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_statements, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_fake_news_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müì∞ Test \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Statement: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mtest_fake_news_prediction\u001b[1;34m(text_input, model, vectorizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mTest the model with custom input\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vectorizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     vectorizer \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Testing Function\n",
    "print(\"\\nüß™ CREATING MODEL TESTING FUNCTION...\")\n",
    "\n",
    "def test_fake_news_prediction(text_input, model=None, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Test the model with custom input\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        model = best_model\n",
    "    if vectorizer is None:\n",
    "        vectorizer = tfidf_vectorizer\n",
    "    \n",
    "    # Clean the input text (same as Member 1's cleaning function)\n",
    "    cleaned_text = re.sub(r'http\\S+', '', text_input.lower())\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', cleaned_text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "    \n",
    "    # Transform to TF-IDF features\n",
    "    text_features = vectorizer.transform([cleaned_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(text_features)[0]\n",
    "    probability = model.predict_proba(text_features)[0]\n",
    "    \n",
    "    return {\n",
    "        'prediction': 'Real' if prediction == 1 else 'Fake',\n",
    "        'confidence': max(probability),\n",
    "        'probabilities': {'Fake': probability[0], 'Real': probability[1]}\n",
    "    }\n",
    "# Test with sample statements\n",
    "test_statements = [\n",
    "    \"The President announced new economic policies today.\",\n",
    "    \"Scientists have discovered that eating chocolate cures cancer completely.\",\n",
    "    \"The stock market closed higher today following positive economic reports.\",\n",
    "    \"Aliens have officially landed and are meeting with world leaders.\"\n",
    "]\n",
    "\n",
    "print(\"\\nüß™ TESTING MODEL WITH SAMPLE STATEMENTS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, statement in enumerate(test_statements, 1):\n",
    "    result = test_fake_news_prediction(statement)\n",
    "    print(f\"\\nüì∞ Test {i}:\")\n",
    "    print(f\"   Statement: {statement}\")\n",
    "    print(f\"   Prediction: {result['prediction']}\")\n",
    "    print(f\"   Confidence: {result['confidence']:.3f}\")\n",
    "    print(f\"   Real probability: {result['probabilities']['Real']:.3f}\")\n",
    "    print(f\"   Fake probability: {result['probabilities']['Fake']:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa60875-b728-4671-b158-fab5dc0f5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç ANALYZING IMPORTANT FEATURES...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Get feature names\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241m.\u001b[39mget_feature_names_out()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Analyze Logistic Regression coefficients\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m models:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#Feature Analysis\n",
    "print(\"\\nüîç ANALYZING IMPORTANT FEATURES...\")\n",
    "\n",
    "import re\n",
    "\n",
    "# Get feature names\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Analyze Logistic Regression coefficients\n",
    "if 'logistic_regression' in models:\n",
    "    lr_coef = models['logistic_regression'].coef_[0]\n",
    "    \n",
    "    # Most indicative of REAL news (positive coefficients)\n",
    "    real_indices = lr_coef.argsort()[-20:]\n",
    "    real_features = [(feature_names[i], lr_coef[i]) for i in real_indices]\n",
    "    \n",
    "    # Most indicative of FAKE news (negative coefficients)  \n",
    "    fake_indices = lr_coef.argsort()[:20]\n",
    "    fake_features = [(feature_names[i], lr_coef[i]) for i in fake_indices]\n",
    "    \n",
    "    print(\"\\nüü¢ TOP 10 WORDS INDICATING REAL NEWS:\")\n",
    "    for word, coef in real_features[-10:]:\n",
    "        print(f\"   {word}: {coef:.3f}\")\n",
    "    \n",
    "    print(\"\\nüî¥ TOP 10 WORDS INDICATING FAKE NEWS:\")\n",
    "    for word, coef in fake_features[:10]:\n",
    "        print(f\"   {word}: {coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5a6b2e-7beb-4b1d-a474-52f7409509bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:37\u001b[1;36m\u001b[0m\n\u001b[1;33m    cv_results[model_name] = {\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#Cross-Validation Analysis\n",
    "print(\"\\nüîÑ CROSS-VALIDATION ANALYSIS...\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Perform detailed cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nüìä Cross-validating {model_name}...\")\n",
    "    \n",
    "    cv_accuracies = []\n",
    "    cv_precisions = []\n",
    "    cv_recalls = []\n",
    "    cv_f1s = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_tfidf, y_train)):\n",
    "        X_fold_train, X_fold_val = X_train_tfidf[train_idx], X_train_tfidf[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        # Train on fold\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "        fold_pred = model.predict(X_fold_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        fold_acc = accuracy_score(y_fold_val, fold_pred)\n",
    "        fold_precision, fold_recall, fold_f1, _ = precision_recall_fscore_support(\n",
    "            y_fold_val, fold_pred, average='weighted'\n",
    "        )\n",
    "cv_accuracies.append(fold_acc)\n",
    "        cv_precisions.append(fold_precision)\n",
    "        cv_recalls.append(fold_recall)\n",
    "        cv_f1s.append(fold_f1)\n",
    "    \n",
    "    cv_results[model_name] = {\n",
    "        'accuracy': cv_accuracies,\n",
    "        'precision': cv_precisions,\n",
    "        'recall': cv_recalls,\n",
    "        'f1': cv_f1s\n",
    "    }\n",
    "    \n",
    "    print(f\"  ‚úÖ {model_name} CV Accuracy: {np.mean(cv_accuracies):.3f} ¬± {np.std(cv_accuracies):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "860d7cf9-7ac5-4da2-8c79-39dda235307c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:29\u001b[1;36m\u001b[0m\n\u001b[1;33m    feature_importance_df.to_csv('../models/tfidf_feature_importance.csv', index=False)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "#Save Results and Documentation\n",
    "print(\"\\nüìÑ SAVING RESULTS AND DOCUMENTATION...\")\n",
    "\n",
    "# Create results summary\n",
    "results_summary = {\n",
    "    'Model': [],\n",
    "    'Test_Accuracy': [],\n",
    "    'CV_Accuracy_Mean': [],\n",
    "    'CV_Accuracy_Std': [],\n",
    "    'Train_Accuracy': []\n",
    "}\n",
    "\n",
    "for model_name in results.keys():\n",
    "    results_summary['Model'].append(model_name.replace('_', ' ').title())\n",
    "    results_summary['Test_Accuracy'].append(f\"{results[model_name]['test_accuracy']:.3f}\")\n",
    "    results_summary['CV_Accuracy_Mean'].append(f\"{np.mean(cv_results[model_name]['accuracy']):.3f}\")\n",
    "    results_summary['CV_Accuracy_Std'].append(f\"{np.std(cv_results[model_name]['accuracy']):.3f}\")\n",
    "    results_summary['Train_Accuracy'].append(f\"{results[model_name]['train_accuracy']:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "results_df.to_csv('../models/tfidf_model_results.csv', index=False)\n",
    "\n",
    "# Save feature importance (if Random Forest)\n",
    "if 'random_forest' in models:\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': models['random_forest'].feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    " feature_importance_df.to_csv('../models/tfidf_feature_importance.csv', index=False)\n",
    "    print(\"‚úÖ Feature importance saved to tfidf_feature_importance.csv\")\n",
    "\n",
    "print(\"\\nüéâ TF-IDF MODEL DEVELOPMENT COMPLETE!\")\n",
    "print(\"üìÅ Files created for team:\")\n",
    "print(\"   - ../models/tfidf_model.pkl (best model)\")\n",
    "print(\"   - ../models/tfidf_vectorizer.pkl\")\n",
    "print(\"   - ../models/tfidf_model_results.csv\")\n",
    "print(\"   - ../models/tfidf_feature_importance.csv\")\n",
    "print(\"\\nüë• Next: Member 3 can now develop BERT model (03_bert_model.ipynb)\")\n",
    "print(\"üí° Member 4 can use these TF-IDF features for the hybrid model!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33eadab1-9468-482d-a280-f1782fc1d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ DEMO FUNCTION FOR TEAM TESTING:\n",
      "üéØ TF-IDF Model Demo\n",
      "==============================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ü§ñ Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Run demo\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mdemo_tfidf_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m, in \u001b[0;36mdemo_tfidf_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m sample_news \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBreaking: New vaccine shows 95\u001b[39m\u001b[38;5;132;01m% e\u001b[39;00m\u001b[38;5;124mffectiveness in clinical trials\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHOCKING: Scientists prove that water is actually dangerous!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEconomic report shows steady growth in manufacturing sector\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCelebrities secretly control the world through hidden messages\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m ]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m news \u001b[38;5;129;01min\u001b[39;00m sample_news:\n\u001b[1;32m---> 19\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_fake_news_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müì∞ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnews[:\u001b[38;5;241m50\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   ü§ñ Prediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mtest_fake_news_prediction\u001b[1;34m(text_input, model, vectorizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mTest the model with custom input\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vectorizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     vectorizer \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "#Quick Demo Function\n",
    "print(\"\\nüé¨ DEMO FUNCTION FOR TEAM TESTING:\")\n",
    "\n",
    "def demo_tfidf_model():\n",
    "    \"\"\"\n",
    "    Quick demo function for team testing\n",
    "    \"\"\"\n",
    "    print(\"üéØ TF-IDF Model Demo\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    sample_news = [\n",
    "        \"Breaking: New vaccine shows 95% effectiveness in clinical trials\",\n",
    "        \"SHOCKING: Scientists prove that water is actually dangerous!\",\n",
    "        \"Economic report shows steady growth in manufacturing sector\",\n",
    "        \"Celebrities secretly control the world through hidden messages\"\n",
    "    ]\n",
    "    \n",
    "    for news in sample_news:\n",
    "        result = test_fake_news_prediction(news)\n",
    "        print(f\"\\nüì∞ {news[:50]}...\")\n",
    "        print(f\"   ü§ñ Prediction: {result['prediction']} (Confidence: {result['confidence']:.2f})\")\n",
    "\n",
    "# Run demo\n",
    "demo_tfidf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d996a4c-ff4c-40c7-aa87-d049c0fc4e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
